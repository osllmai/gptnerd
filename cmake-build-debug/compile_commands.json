[
{
  "directory": "D:/LLMS/LlamaGPTJ-chat-main/cmake-build-debug",
  "command": "C:\\PROGRA~1\\JETBRA~1\\CLION2~1.1\\bin\\mingw\\bin\\gcc.exe -ID:/LLMS/LlamaGPTJ-chat-main/cmake-build-debug -ID:/LLMS/LlamaGPTJ-chat-main/gpt4all-backend/llama.cpp/. -g -std=gnu11 -fdiagnostics-color=always -Wall -Wextra -Wpedantic -Wcast-qual -Wdouble-promotion -Wshadow -Wstrict-prototypes -Wpointer-arith -mf16c -mfma -mavx -mavx2 -o gpt4all-backend\\llama.cpp\\CMakeFiles\\ggml.dir\\ggml.c.obj -c D:\\LLMS\\LlamaGPTJ-chat-main\\gpt4all-backend\\llama.cpp\\ggml.c",
  "file": "D:\\LLMS\\LlamaGPTJ-chat-main\\gpt4all-backend\\llama.cpp\\ggml.c",
  "output": "gpt4all-backend\\llama.cpp\\CMakeFiles\\ggml.dir\\ggml.c.obj"
},
{
  "directory": "D:/LLMS/LlamaGPTJ-chat-main/cmake-build-debug",
  "command": "C:\\PROGRA~1\\JETBRA~1\\CLION2~1.1\\bin\\mingw\\bin\\G__~1.EXE -ID:/LLMS/LlamaGPTJ-chat-main/cmake-build-debug -ID:/LLMS/LlamaGPTJ-chat-main/gpt4all-backend/llama.cpp/. -g -std=gnu++11 -fdiagnostics-color=always -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -mf16c -mfma -mavx -mavx2 -o gpt4all-backend\\llama.cpp\\CMakeFiles\\llama.dir\\llama.cpp.obj -c D:\\LLMS\\LlamaGPTJ-chat-main\\gpt4all-backend\\llama.cpp\\llama.cpp",
  "file": "D:\\LLMS\\LlamaGPTJ-chat-main\\gpt4all-backend\\llama.cpp\\llama.cpp",
  "output": "gpt4all-backend\\llama.cpp\\CMakeFiles\\llama.dir\\llama.cpp.obj"
},
{
  "directory": "D:/LLMS/LlamaGPTJ-chat-main/cmake-build-debug",
  "command": "C:\\PROGRA~1\\JETBRA~1\\CLION2~1.1\\bin\\mingw\\bin\\G__~1.EXE -ID:/LLMS/LlamaGPTJ-chat-main/cmake-build-debug -ID:/LLMS/LlamaGPTJ-chat-main/gpt4all-backend/llama.cpp/. -g -std=gnu++20 -fdiagnostics-color=always -o gpt4all-backend\\CMakeFiles\\llmodel.dir\\gptj.cpp.obj -c D:\\LLMS\\LlamaGPTJ-chat-main\\gpt4all-backend\\gptj.cpp",
  "file": "D:\\LLMS\\LlamaGPTJ-chat-main\\gpt4all-backend\\gptj.cpp",
  "output": "gpt4all-backend\\CMakeFiles\\llmodel.dir\\gptj.cpp.obj"
},
{
  "directory": "D:/LLMS/LlamaGPTJ-chat-main/cmake-build-debug",
  "command": "C:\\PROGRA~1\\JETBRA~1\\CLION2~1.1\\bin\\mingw\\bin\\G__~1.EXE -ID:/LLMS/LlamaGPTJ-chat-main/cmake-build-debug -ID:/LLMS/LlamaGPTJ-chat-main/gpt4all-backend/llama.cpp/. -g -std=gnu++20 -fdiagnostics-color=always -o gpt4all-backend\\CMakeFiles\\llmodel.dir\\llamamodel.cpp.obj -c D:\\LLMS\\LlamaGPTJ-chat-main\\gpt4all-backend\\llamamodel.cpp",
  "file": "D:\\LLMS\\LlamaGPTJ-chat-main\\gpt4all-backend\\llamamodel.cpp",
  "output": "gpt4all-backend\\CMakeFiles\\llmodel.dir\\llamamodel.cpp.obj"
},
{
  "directory": "D:/LLMS/LlamaGPTJ-chat-main/cmake-build-debug",
  "command": "C:\\PROGRA~1\\JETBRA~1\\CLION2~1.1\\bin\\mingw\\bin\\G__~1.EXE -ID:/LLMS/LlamaGPTJ-chat-main/cmake-build-debug -ID:/LLMS/LlamaGPTJ-chat-main/gpt4all-backend/llama.cpp/. -g -std=gnu++20 -fdiagnostics-color=always -o gpt4all-backend\\CMakeFiles\\llmodel.dir\\llama.cpp\\examples\\common.cpp.obj -c D:\\LLMS\\LlamaGPTJ-chat-main\\gpt4all-backend\\llama.cpp\\examples\\common.cpp",
  "file": "D:\\LLMS\\LlamaGPTJ-chat-main\\gpt4all-backend\\llama.cpp\\examples\\common.cpp",
  "output": "gpt4all-backend\\CMakeFiles\\llmodel.dir\\llama.cpp\\examples\\common.cpp.obj"
},
{
  "directory": "D:/LLMS/LlamaGPTJ-chat-main/cmake-build-debug",
  "command": "C:\\PROGRA~1\\JETBRA~1\\CLION2~1.1\\bin\\mingw\\bin\\G__~1.EXE -ID:/LLMS/LlamaGPTJ-chat-main/cmake-build-debug -ID:/LLMS/LlamaGPTJ-chat-main/gpt4all-backend/llama.cpp/. -g -std=gnu++20 -fdiagnostics-color=always -o gpt4all-backend\\CMakeFiles\\llmodel.dir\\llmodel_c.cpp.obj -c D:\\LLMS\\LlamaGPTJ-chat-main\\gpt4all-backend\\llmodel_c.cpp",
  "file": "D:\\LLMS\\LlamaGPTJ-chat-main\\gpt4all-backend\\llmodel_c.cpp",
  "output": "gpt4all-backend\\CMakeFiles\\llmodel.dir\\llmodel_c.cpp.obj"
},
{
  "directory": "D:/LLMS/LlamaGPTJ-chat-main/cmake-build-debug",
  "command": "C:\\PROGRA~1\\JETBRA~1\\CLION2~1.1\\bin\\mingw\\bin\\G__~1.EXE -ID:/LLMS/LlamaGPTJ-chat-main/cmake-build-debug -ID:/LLMS/LlamaGPTJ-chat-main/gpt4all-backend/llama.cpp/. -g -std=gnu++20 -fdiagnostics-color=always -o gpt4all-backend\\CMakeFiles\\llmodel.dir\\mpt.cpp.obj -c D:\\LLMS\\LlamaGPTJ-chat-main\\gpt4all-backend\\mpt.cpp",
  "file": "D:\\LLMS\\LlamaGPTJ-chat-main\\gpt4all-backend\\mpt.cpp",
  "output": "gpt4all-backend\\CMakeFiles\\llmodel.dir\\mpt.cpp.obj"
},
{
  "directory": "D:/LLMS/LlamaGPTJ-chat-main/cmake-build-debug",
  "command": "C:\\PROGRA~1\\JETBRA~1\\CLION2~1.1\\bin\\mingw\\bin\\G__~1.EXE -ID:/LLMS/LlamaGPTJ-chat-main/cmake-build-debug -ID:/LLMS/LlamaGPTJ-chat-main/gpt4all-backend/llama.cpp/. -g -std=gnu++20 -fdiagnostics-color=always -o gpt4all-backend\\CMakeFiles\\llmodel.dir\\utils.cpp.obj -c D:\\LLMS\\LlamaGPTJ-chat-main\\gpt4all-backend\\utils.cpp",
  "file": "D:\\LLMS\\LlamaGPTJ-chat-main\\gpt4all-backend\\utils.cpp",
  "output": "gpt4all-backend\\CMakeFiles\\llmodel.dir\\utils.cpp.obj"
},
{
  "directory": "D:/LLMS/LlamaGPTJ-chat-main/cmake-build-debug",
  "command": "C:\\PROGRA~1\\JETBRA~1\\CLION2~1.1\\bin\\mingw\\bin\\G__~1.EXE -ID:/LLMS/LlamaGPTJ-chat-main/cmake-build-debug -ID:/LLMS/LlamaGPTJ-chat-main/gpt4all-backend/llama.cpp/. -g -std=gnu++20 -fdiagnostics-color=always -o src\\CMakeFiles\\chat.dir\\chat.cpp.obj -c D:\\LLMS\\LlamaGPTJ-chat-main\\src\\chat.cpp",
  "file": "D:\\LLMS\\LlamaGPTJ-chat-main\\src\\chat.cpp",
  "output": "src\\CMakeFiles\\chat.dir\\chat.cpp.obj"
}
]