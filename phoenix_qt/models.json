{
  "offlineModels": [
    {
      "order": "a",
      "md5sum": "c87ad09e1e4c8f9c35a5fcef52b6f1c9",
      "name": "Llama 3 8B Instruct",
      "filename": "Meta-Llama-3-8B-Instruct.Q4_0.gguf",
      "filesize": "4.66",
      "requires": "2.7.1",
      "ramrequired": "8",
      "parameters": "8 billion",
      "quant": "q4_0",
      "type": "LLaMA3",
      "description": "<ul><li>Fast responses</li><li>Chat based model</li><li>Accepts system prompts in Llama 3 format</li><li>Trained by Meta</li></ul>",
      "url": "https://GPT4all.io/models/gguf/Meta-Llama-3-8B-Instruct.Q4_0.gguf",
      "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
      "systemPrompt": "",
      "icon": "images/image3.svg"
    },
    {
      "order": "b",
      "md5sum": "a5f6b4eabd3992da4d7fb7f020f921eb",
      "name": "Nous Hermes 2 Mistral DPO",
      "filename": "Nous-Hermes-2-Mistral-7B-DPO.Q4_0.gguf",
      "filesize": "4.10",
      "requires": "2.7.1",
      "ramrequired": "8",
      "parameters": "7 billion",
      "quant": "q4_0",
      "type": "Mistral",
      "description": "<strong>Good overall fast chat model</strong><br><ul><li>Fast responses</li><li>Chat based model</li><li>Accepts system prompts in ChatML format</li><li>Trained by Mistral AI<li>Finetuned by Nous Research on the OpenHermes-2.5 dataset<li>Licensed for commercial use</ul>",
      "url": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF/resolve/main/Nous-Hermes-2-Mistral-7B-DPO.Q4_0.gguf",
      "promptTemplate": "<|im_start|>user\n%1<|im_end|>\n<|im_start|>assistant\n%2<|im_end|>\n",
      "systemPrompt": "",
      "icon": "images/mistral-ai-icon.svg"
    },
    {
      "order": "c",
      "md5sum": "97463be739b50525df56d33b26b00852",
      "name": "Mistral Instruct",
      "filename": "mistral-7b-instruct-v0.1.Q4_0.gguf",
      "filesize": "4.10",
      "requires": "2.5.0",
      "ramrequired": "8",
      "parameters": "7 billion",
      "quant": "q4_0",
      "type": "Mistral",
      "systemPrompt": "",
      "description": "<strong>Strong overall fast instruction following model</strong><br><ul><li>Fast responses</li><li>Trained by Mistral AI<li>Uncensored</li><li>Licensed for commercial use</li></ul>",
      "url": "https://GPT4all.io/models/gguf/mistral-7b-instruct-v0.1.Q4_0.gguf",
      "promptTemplate": "[INST] %1 [/INST]",
      "icon": "images/mistral-ai-icon.svg"
    },
    {
      "order": "d",
      "md5sum": "8a9c75bcd8a66b7693f158ec96924eeb",
      "name": "Llama 3.1 8B Instruct 128k",
      "filename": "Meta-Llama-3.1-8B-Instruct-128k-Q4_0.gguf",
      "filesize": "4.66",
      "requires": "3.1.1",
      "ramrequired": "8",
      "parameters": "8 billion",
      "quant": "q4_0",
      "type": "LLaMA3",
      "description": "<ul><li><strong>For advanced users only. Not recommended for use on Windows or Linux without selecting CUDA due to speed issues.</strong></li><li>Fast responses</li><li>Chat based model</li><li>Large context size of 128k</li><li>Accepts agentic system prompts in Llama 3.1 format</li><li>Trained by Meta</li></ul>",
      "url": "https://huggingface.co/GPT4All-Community/Meta-Llama-3.1-8B-Instruct-128k/resolve/main/Meta-Llama-3.1-8B-Instruct-128k-Q4_0.gguf",
      "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2",
      "systemPrompt": "<|start_header_id|>system<|end_header_id|>\nCutting Knowledge Date: December 2023\n\nYou are a helpful assistant.<|eot_id|>",
      "icon": "images/image3.svg"
    },
    {
      "order": "e",
      "md5sum": "f692417a22405d80573ac10cb0cd6c6a",
      "name": "Mistral OpenOrca",
      "filename": "mistral-7b-openorca.gguf2.Q4_0.gguf",
      "filesize": "4.10",
      "requires": "2.7.1",
      "ramrequired": "8",
      "parameters": "7 billion",
      "quant": "q4_0",
      "type": "Mistral",
      "description": "<strong>Strong overall fast chat model</strong><br><ul><li>Fast responses</li><li>Chat based model</li><li>Trained by Mistral AI</ul>",
      "url": "https://GPT4all.io/models/gguf/mistral-7b-openorca.gguf2.Q4_0.gguf",
      "promptTemplate": "<|im_start|>user\n%1<|im_end|>\n<|im_start|>assistant\n%2<|im_end|>\n",
      "systemPrompt": "<|im_start|>system\nYou are MistralOrca, a large language model trained by Alignment Lab AI.\n<|im_end|>\n",
      "icon": "images/mistral-ai-icon.svg"
    },
    {
      "order": "g",
      "md5sum": "00c8593ba57f5240f59662367b3ed4a5",
      "name": "Orca 2 (Medium)",
      "filename": "orca-2-7b.Q4_0.gguf",
      "filesize": "3.82",
      "requires": "2.5.2",
      "ramrequired": "8",
      "parameters": "7 billion",
      "quant": "q4_0",
      "type": "LLaMA2",
      "systemPrompt": "",
      "description": "<ul><li>Instruction based<li>Trained by Microsoft<li>Cannot be used commercially</ul>",
      "url": "https://GPT4all.io/models/gguf/orca-2-7b.Q4_0.gguf",
      "icon": "images/image3.svg"
    },
    {
      "order": "h",
      "md5sum": "3c0d63c4689b9af7baa82469a6f51a19",
      "name": "Orca 2 (Full)",
      "filename": "orca-2-13b.Q4_0.gguf",
      "filesize": "7.36",
      "requires": "2.5.2",
      "ramrequired": "16",
      "parameters": "13 billion",
      "quant": "q4_0",
      "type": "LLaMA2",
      "systemPrompt": "",
      "description": "<ul><li>Instruction based<li>Trained by Microsoft<li>Cannot be used commercially</ul>",
      "url": "https://GPT4all.io/models/gguf/orca-2-13b.Q4_0.gguf",
      "icon": "images/image3.svg"
    },
    {
      "order": "i",
      "md5sum": "5aff90007499bce5c64b1c0760c0b186",
      "name": "Wizard v1.2",
      "filename": "wizardlm-13b-v1.2.Q4_0.gguf",
      "filesize": "7.36",
      "requires": "2.5.0",
      "ramrequired": "16",
      "parameters": "13 billion",
      "quant": "q4_0",
      "type": "LLaMA2",
      "systemPrompt": "",
      "description": "<strong>Strong overall larger model</strong><br><ul><li>Instruction based<li>Gives very long responses<li>Finetuned with only 1k of high-quality data<li>Trained by Microsoft and Peking University<li>Cannot be used commercially</ul>",
      "url": "https://GPT4all.io/models/gguf/wizardlm-13b-v1.2.Q4_0.gguf",
      "icon": "images/image3.svg"
    },
    {
      "order": "j",
      "md5sum": "31b47b4e8c1816b62684ac3ca373f9e1",
      "name": "Ghost 7B v0.9.1",
      "filename": "ghost-7b-v0.9.1-Q4_0.gguf",
      "filesize": "4.10",
      "requires": "2.7.1",
      "ramrequired": "8",
      "parameters": "7 billion",
      "quant": "q4_0",
      "type": "Mistral",
      "description": "<strong>Ghost 7B v0.9.1</strong> fast, powerful and smooth for Vietnamese and English languages.",
      "url": "https://huggingface.co/lamhieu/ghost-7b-v0.9.1-gguf/resolve/main/ghost-7b-v0.9.1-Q4_0.gguf",
      "promptTemplate": "<|user|>\n%1</s>\n<|assistant|>\n%2</s>\n",
      "systemPrompt": "<|system|>\nYou are Ghost created by Lam Hieu. You are a helpful and knowledgeable assistant. You like to help and always give honest information, in its original language. In communication, you are always respectful, equal and promote positive behavior.\n</s>",
      "icon": "images/mistral-ai-icon.svg"
    },
    {
      "order": "k",
      "md5sum": "3d12810391d04d1153b692626c0c6e16",
      "name": "Hermes",
      "filename": "nous-hermes-llama2-13b.Q4_0.gguf",
      "filesize": "7.36",
      "requires": "2.5.0",
      "ramrequired": "16",
      "parameters": "13 billion",
      "quant": "q4_0",
      "type": "LLaMA2",
      "systemPrompt": "",
      "description": "<strong>Extremely good model</strong><br><ul><li>Instruction based<li>Gives long responses<li>Curated with 300,000 uncensored instructions<li>Trained by Nous Research<li>Cannot be used commercially</ul>",
      "url": "https://GPT4all.io/models/gguf/nous-hermes-llama2-13b.Q4_0.gguf",
      "promptTemplate": "### Instruction:\n%1\n\n### Response:\n",
      "icon": "images/image3.svg"
    },
    {
      "order": "l",
      "md5sum": "40388eb2f8d16bb5d08c96fdfaac6b2c",
      "name": "Snoozy",
      "filename": "GPT4all-13b-snoozy-q4_0.gguf",
      "filesize": "7.36",
      "requires": "2.5.0",
      "ramrequired": "16",
      "parameters": "13 billion",
      "quant": "q4_0",
      "type": "LLaMA",
      "systemPrompt": "",
      "description": "<strong>Very good overall model</strong><br><ul><li>Instruction based<li>Based on the same dataset as Groovy<li>Slower than Groovy, with higher quality responses<li>Trained by Nomic AI<li>Cannot be used commercially</ul>",
      "url": "https://GPT4all.io/models/gguf/GPT4all-13b-snoozy-q4_0.gguf",
      "icon": "images/image3.svg"
    },
    {
      "order": "m",
      "md5sum": "15dcb4d7ea6de322756449c11a0b7545",
      "name": "MPT Chat",
      "filename": "mpt-7b-chat-newbpe-q4_0.gguf",
      "filesize": "3.91",
      "requires": "2.7.1",
      "removedIn": "2.7.3",
      "ramrequired": "8",
      "parameters": "7 billion",
      "quant": "q4_0",
      "type": "MPT",
      "description": "<strong>Good model with novel architecture</strong><br><ul><li>Fast responses<li>Chat based<li>Trained by Mosaic ML<li>Cannot be used commercially</ul>",
      "url": "https://GPT4all.io/models/gguf/mpt-7b-chat-newbpe-q4_0.gguf",
      "promptTemplate": "<|im_start|>user\n%1<|im_end|>\n<|im_start|>assistant\n%2<|im_end|>\n",
      "systemPrompt": "<|im_start|>system\n- You are a helpful assistant chatbot trained by MosaicML.\n- You answer questions.\n- You are excited to be able to help the user, but will refuse to do anything that could be considered harmful to the user.\n- You are more than just an information source, you are also able to write poetry, short stories, and make jokes.<|im_end|>\n",
      "icon": "images/image3.svg"
    },
    {
      "order": "n",
      "md5sum": "ab5d8e8a2f79365ea803c1f1d0aa749d",
      "name": "MPT Chat",
      "filename": "mpt-7b-chat.gguf4.Q4_0.gguf",
      "filesize": "3.79",
      "requires": "2.7.3",
      "ramrequired": "8",
      "parameters": "7 billion",
      "quant": "q4_0",
      "type": "MPT",
      "description": "<strong>Good model with novel architecture</strong><br><ul><li>Fast responses<li>Chat based<li>Trained by Mosaic ML<li>Cannot be used commercially</ul>",
      "url": "https://GPT4all.io/models/gguf/mpt-7b-chat.gguf4.Q4_0.gguf",
      "promptTemplate": "<|im_start|>user\n%1<|im_end|>\n<|im_start|>assistant\n%2<|im_end|>\n",
      "systemPrompt": "<|im_start|>system\n- You are a helpful assistant chatbot trained by MosaicML.\n- You answer questions.\n- You are excited to be able to help the user, but will refuse to do anything that could be considered harmful to the user.\n- You are more than just an information source, you are also able to write poetry, short stories, and make jokes.<|im_end|>\n",
      "icon": "images/image3.svg"
    },
    {
      "order": "o",
      "md5sum": "f8347badde9bfc2efbe89124d78ddaf5",
      "name": "Phi-3 Mini Instruct",
      "filename": "Phi-3-mini-4k-instruct.Q4_0.gguf",
      "filesize": "2.17",
      "requires": "2.7.1",
      "ramrequired": "4",
      "parameters": "4 billion",
      "quant": "q4_0",
      "type": "Phi-3",
      "description": "<ul><li>Very fast responses</li><li>Chat based model</li><li>Accepts system prompts in Phi-3 format</li><li>Trained by Microsoft</li><li>License: <a href=\"https://opensource.org/license/mit\">MIT</a></li><li>No restrictions on commercial use</li></ul>",
      "url": "https://GPT4all.io/models/gguf/Phi-3-mini-4k-instruct.Q4_0.gguf",
      "promptTemplate": "<|user|>\n%1<|end|>\n<|assistant|>\n%2<|end|>\n",
      "systemPrompt": "",
      "icon": "images/image3.svg"
    },
    {
      "order": "p",
      "md5sum": "0e769317b90ac30d6e09486d61fefa26",
      "name": "Mini Orca (Small)",
      "filename": "orca-mini-3b-gguf2-q4_0.gguf",
      "filesize": "1.97",
      "requires": "2.5.0",
      "ramrequired": "4",
      "parameters": "3 billion",
      "quant": "q4_0",
      "type": "OpenLLaMa",
      "description": "<strong>Small version of new model with novel dataset</strong><br><ul><li>Very fast responses</li><li>Instruction based</li><li>Explain tuned datasets</li><li>Orca Research Paper dataset construction approaches</li><li>Cannot be used commercially</li></ul>",
      "url": "https://GPT4all.io/models/gguf/orca-mini-3b-gguf2-q4_0.gguf",
      "promptTemplate": "### User:\n%1\n\n### Response:\n",
      "systemPrompt": "### System:\nYou are an AI assistant that follows instruction extremely well. Help as much as you can.\n\n",
      "icon": "images/image3.svg"
    },
    {
      "order": "q",
      "md5sum": "c232f17e09bca4b7ee0b5b1f4107c01e",
      "disableGUI": "true",
      "name": "Replit",
      "filename": "replit-code-v1_5-3b-newbpe-q4_0.gguf",
      "filesize": "1.953",
      "requires": "2.6.0",
      "ramrequired": "4",
      "parameters": "3 billion",
      "quant": "q4_0",
      "type": "Replit",
      "systemPrompt": "",
      "promptTemplate": "%1",
      "description": "<strong>Trained on subset of the Stack</strong><br><ul><li>Code completion based<li>Licensed for commercial use<li>WARNING: Not available for chat GUI</ul>",
      "url": "https://GPT4all.io/models/gguf/replit-code-v1_5-3b-newbpe-q4_0.gguf",
      "icon": "images/image3.svg"
    },
    {
      "order": "r",
      "md5sum": "70841751ccd95526d3dcfa829e11cd4c",
      "disableGUI": "true",
      "name": "Starcoder",
      "filename": "starcoder-newbpe-q4_0.gguf",
      "filesize": "8.98",
      "requires": "2.6.0",
      "ramrequired": "4",
      "parameters": "7 billion",
      "quant": "q4_0",
      "type": "Starcoder",
      "systemPrompt": "",
      "promptTemplate": "%1",
      "description": "<strong>Trained on subset of the Stack</strong><br><ul><li>Code completion based<li>WARNING: Not available for chat GUI</ul>",
      "url": "https://GPT4all.io/models/gguf/starcoder-newbpe-q4_0.gguf",
      "icon": "images/image3.svg"
    },
    {
      "order": "s",
      "md5sum": "e973dd26f0ffa6e46783feaea8f08c83",
      "disableGUI": "true",
      "name": "Rift coder",
      "filename": "rift-coder-v0-7b-q4_0.gguf",
      "filesize": "3.82",
      "requires": "2.5.0",
      "ramrequired": "8",
      "parameters": "7 billion",
      "quant": "q4_0",
      "type": "LLaMA",
      "systemPrompt": "",
      "promptTemplate": "%1",
      "description": "<strong>Trained on collection of Python and TypeScript</strong><br><ul><li>Code completion based<li>WARNING: Not available for chat GUI</li>",
      "url": "https://GPT4all.io/models/gguf/rift-coder-v0-7b-q4_0.gguf",
      "icon": "images/image3.svg"
    },
    {
      "order": "t",
      "md5sum": "e479e6f38b59afc51a470d1953a6bfc7",
      "disableGUI": "true",
      "name": "SBert",
      "filename": "all-MiniLM-L6-v2-f16.gguf",
      "filesize": "0.45",
      "requires": "2.5.0",
      "removedIn": "2.7.4",
      "ramrequired": "1",
      "parameters": "40 million",
      "quant": "f16",
      "type": "Bert",
      "embeddingModel": true,
      "systemPrompt": "",
      "description": "<strong>LocalDocs text embeddings model</strong><br><ul><li>For use with LocalDocs feature<li>Used for retrieval augmented generation (RAG)",
      "url": "https://GPT4all.io/models/gguf/all-MiniLM-L6-v2-f16.gguf",
      "icon": "images/image3.svg"
    },
    {
      "order": "u",
      "md5sum": "dd90e2cb7f8e9316ac3796cece9883b5",
      "name": "SBert",
      "filename": "all-MiniLM-L6-v2.gguf2.f16.gguf",
      "filesize": "0.45",
      "requires": "2.7.4",
      "removedIn": "3.0.0",
      "ramrequired": "1",
      "parameters": "40 million",
      "quant": "f16",
      "type": "Bert",
      "embeddingModel": true,
      "description": "<strong>LocalDocs text embeddings model</strong><br><ul><li>For use with LocalDocs feature<li>Used for retrieval augmented generation (RAG)",
      "url": "https://GPT4all.io/models/gguf/all-MiniLM-L6-v2.gguf2.f16.gguf",
      "icon": "images/image3.svg"
    },
    {
      "order": "v",
      "md5sum": "919de4dd6f25351bcb0223790db1932d",
      "name": "EM German Mistral",
      "filename": "em_german_mistral_v01.Q4_0.gguf",
      "filesize": "4.10",
      "requires": "2.5.0",
      "ramrequired": "8",
      "parameters": "7 billion",
      "quant": "q4_0",
      "type": "Mistral",
      "description": "<strong>Mistral-based model for German-language applications</strong><br><ul><li>Fast responses</li><li>Chat based model</li><li>Trained by ellamind<li>Finetuned on German instruction and chat data</a><li>Licensed for commercial use</ul>",
      "url": "https://huggingface.co/TheBloke/em_german_mistral_v01-GGUF/resolve/main/em_german_mistral_v01.Q4_0.gguf",
      "promptTemplate": "USER: %1 ASSISTANT: ",
      "systemPrompt": "Du bist ein hilfreicher Assistent. ",
      "icon": "images/mistral-ai-icon.svg"
    },
    {
      "order": "z",
      "md5sum": "a8c5a783105f87a481543d4ed7d7586d",
      "name": "Qwen2-1.5B-Instruct",
      "filename": "qwen2-1_5b-instruct-q4_0.gguf",
      "filesize": "0.93",
      "requires": "3.0",
      "ramrequired": "4",
      "parameters": "1.5 billion",
      "quant": "q4_0",
      "type": "qwen2",
      "description": "<ul><li>Very fast responses</li><li>Instruction based model</li><li>Usage of LocalDocs (RAG): Highly recommended</li><li>Supports context length of up to 32768</li><li>Trained and finetuned by Qwen (Alibaba Cloud)</li><li>License: <a href=\"https://www.apache.org/licenses/LICENSE-2.0.html/\">Apache 2.0</a></li></ul>",
      "url": "https://huggingface.co/Qwen/Qwen2-1.5B-Instruct-GGUF/resolve/main/qwen2-1_5b-instruct-q4_0.gguf",
      "promptTemplate": "<|im_start|>user\n%1<|im_end|>\n<|im_start|>assistant\n%2<|im_end|>",
      "systemPrompt": "<|im_start|>system\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.<|im_end|>\n",
      "icon": "images/image3.svg"
    }
  ],

  "onlineModels": {
    "OpenAI": {
      "companyInfo": {
        "name": "OpenAI",
        "organizationName": "OpenAI"
      },
      "models": [
        {
          "number": "1",
          "name": "GPT-4O Mini",
          "type": "Text Generation",
          "description": "GPT-4O Mini is a text generation model that can generate human-like text based on the input text.",
          "contextWindows": "128K tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "2",
          "name": "GPT-4O",
          "type": "Text Generation",
          "description": "GPT-4O is a text generation model with enhanced capabilities for handling complex prompts and generating human-like text.",
          "contextWindows": "128K tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "3",
          "name": "GPT-4 Turbo",
          "type": "Text Generation",
          "description": "GPT-4 Turbo is a cost-effective version of GPT-4 with high-quality text generation capabilities.",
          "contextWindows": "128K tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "4",
          "name": "GPT-4 Turbo Vision",
          "type": "Multimodal",
          "description": "GPT-4 Turbo Vision extends GPT-4 capabilities by supporting text and image inputs for multimodal understanding.",
          "contextWindows": "128K tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "5",
          "name": "GPT-3.5 Turbo",
          "type": "Text Generation",
          "description": "GPT-3.5 Turbo is a reliable text generation model for shorter context windows and everyday applications.",
          "contextWindows": "16K tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "6",
          "name": "O1-Preview",
          "type": "Text Generation",
          "description": "O1-Preview is a beta model designed for experimentation and early access to OpenAI's latest developments.",
          "contextWindows": "128K tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "7",
          "name": "O1-Mini",
          "type": "Text Generation",
          "description": "O1-Mini is a lightweight text generation model optimized for fast performance.",
          "contextWindows": "128K tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "8",
          "name": "GPT-4 8K",
          "type": "Text Generation",
          "description": "GPT-4 8K is optimized for handling shorter context windows while delivering high-quality outputs.",
          "contextWindows": "16K tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "9",
          "name": "GPT-4 32K",
          "type": "Text Generation",
          "description": "GPT-4 32K provides extended context capabilities suitable for complex and long-form text generation.",
          "contextWindows": "32K tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "10",
          "name": "GPT-4o-2024-11-20",
          "type": "Text Generation",
          "description": "GPT-4o-2024-11-20 is a text generation model that can generate human-like text based on the input text.",
          "contextWindows": "128K tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "10",
          "name": "GPT-4o-2024-08-06",
          "type": "Text Generation",
          "description": "GPT-4o-2024-11-20 is a text generation model that can generate human-like text based on the input text.",
          "contextWindows": "128K tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "10",
          "name": "GPT-4o-2024-05-13",
          "type": "Text Generation",
          "description": "GPT-4o-2024-11-20 is a text generation model that can generate human-like text based on the input text.",
          "contextWindows": "128K tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        }
      ]
    },

    "Anthropic (Claude)": {
      "companyInfo": {
        "name": "Anthropic",
        "organizationName": "Anthropic"
      },
      "models": [
        {
          "number": "1",
          "name": "Claude 3.5 Haiku",
          "type": "Text Generation",
          "description": "Claude 3.5 Haiku is a text generation model that can generate haikus based on the input text.",
          "contextWindows": "200k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "2",
          "name": "Claude 3.5 Sonnet New",
          "type": "Text Generation",
          "description": "Claude 3.5 Sonnet New is a text generation model that can generate sonnets based on the input text.",
          "contextWindows": "200k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "3",
          "name": "Claude 3.5 Sonnet",
          "type": "Text Generation",
          "description": "Claude 3.5 Sonnet is a text generation model that can generate sonnets based on the input text.",
          "contextWindows": "200k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "4",
          "name": "Claude 3 Haiku",
          "type": "Text Generation",
          "description": "Claude 3 Haiku is a text generation model that can generate haikus based on the input text.",
          "contextWindows": "200k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },

        {
          "number": "5",
          "name": "Claude 3 Opus",
          "type": "Text Generation",
          "description": "Claude 3 Opus is a text generation model that can generate opuses based on the input text.",
          "contextWindows": "200k (Pricey) Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "6",
          "name": "Claude 3 Sonnet",
          "type": "Text Generation",
          "description": "Claude 3 Sonnet is a text generation model that can generate sonnets based on the input text.",
          "contextWindows": "200k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "7",
          "name": "Claude 2.1",
          "type": "Text Generation",
          "description": "Claude 2.1 is a text generation model that can generate human-like text based on the input text.",
          "contextWindows": "200k (Pricey) Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "8",
          "name": "Claude Instant",
          "type": "Text Generation",
          "description": "Claude Instant is a text generation model that can generate human-like text based on the input text.",
          "contextWindows": "100k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        }
      ]
    },
    "Google": {
      "companyInfo": {
        "name": "Google",
        "organizationName": "Google LLC"
      },
      "models": [
        {
          "number": "1",
          "name": "Gemini 1.5 Flash",
          "type": "Text",
          "description": "Gemini 1.5 Flash is a highly capable text generation model.",
          "contextWindows": "1024k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "2",
          "name": "Gemini 1.5 Pro",
          "type": "Text",
          "description": "Gemini 1.5 Pro is a text generation model with advanced capabilities.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "3",
          "name": "Gemma 2 9B It",
          "type": "Text",
          "description": "Gemma 2 9B It is a text generation model with advanced capabilities.",
          "contextWindows": "8k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "4",
          "name": "Gemma 7B It",
          "type": "Text",
          "description": "Gemma 7B It is a text generation model with advanced capabilities.",
          "contextWindows": "8k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "5",
          "name": "Gemma 7B It Lora",
          "type": "Text",
          "description": "Gemma 7B It Lora is a text generation model with advanced capabilities.",
          "contextWindows": "8k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id | >assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "6",
          "name": "Gemma 2B It Lora",
          "type": "Text",
          "description": "Gemma 2B It Lora is a text generation model with advanced capabilities.",
          "contextWindows": "8k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "7",
          "name": "Google Palm 2",
          "type": "Text",
          "description": "Google Palm 2 is a text generation model with advanced capabilities.",
          "contextWindows": "36k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "8",
          "name": "Google Gemini Pro",
          "type": "Text",
          "description": "Google Gemini Pro is a text generation model with advanced capabilities.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "9",
          "name": "Google Palm 2 32K",
          "type": "Text",
          "description": "Google Palm 2 with extended context for large tasks.",
          "contextWindows": "128k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        }
      ]
    },

    "Dolphin Mixtal Models": {
      "companyInfo": {
        "name": "Dolphin Mixtal",
        "organizationName": "Dolphin Mixtal Inc."
      },
      "models": [
        {
          "numner": "1",
          "name": "Dolphin Mixtal 8×22B",
          "type": "Text",
          "description": "Large-scale text generation model optimized for long contexts.",
          "contextWindows": "64k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "2",
          "name": "Dolphin Mixtal 8×7B",
          "type": "Text",
          "description": "Text generation model with advanced capabilities for handling complex prompts.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        }
      ]
    },
    "Qwen Models": {
      "companyInfo": {
        "name": "Qwen",
        "organizationName": "Qwen AI Labs"
      },
      "models": [
        {
          "number": "1",
          "name": "Qwen Qwq 32B Preview",
          "type": "Text",
          "description": "Preview of the Qwen Qwq series with robust text generation.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },

        {
          "number": "2",
          "name": "Qwen-2.5 Coder 32B Instruct",
          "type": "Text",
          "description": "Instruction-following model with large-scale capabilities.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "3",
          "name": "Qwen-2.5 72B Instruct",
          "type": "Text",
          "description": "Large-scale instruction-following model with advanced capabilities.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "4",
          "name": "Qwen-2.5 7B Instruct",
          "type": "Text",
          "description": "Instruction-following model with large-scale capabilities.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "5",
          "name": "Qwen-2 72B Instruct",
          "type": "Text",
          "description": "Large-scale instruction-following model with advanced capabilities.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },

        {
          "number": "6",
          "name": "Qwen-1.5 14B Chat Awq",
          "type": "Text",
          "description": "Large-scale chat model with advanced capabilities.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "7",
          "name": "Qwen-1.5 7B Chat Awq",
          "type": "Text",
          "description": "Chat model with large-scale capabilities.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "8",
          "name": "Qwen-1.5 0.5B Chat",
          "type": "Text",
          "description": "Compact chat model with large-scale capabilities.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "9",
          "name": "Qwen-1.5 1.8B Chat",
          "type": "Text",
          "description": "Chat model with large-scale capabilities.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        }
      ]
    },
    "Meta Llama Models": {
      "companyInfo": {
        "name": "Meta",
        "organizationName": "Meta Platforms, Inc."
      },
      "models": [
        {
          "number": "1",
          "name": "Meta Llama 3.3 70B Instruct",
          "type": "Text",
          "description": "Advanced instruction-following model with large-scale capabilities.",
          "contextWindows": "128k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "2",
          "name": "Meta Llama 3.2 90B Vision Instruct",
          "type": "Text",
          "description": "Vision and text instruct model with extended capabilities.",
          "contextWindows": "Not listed Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "3",
          "name": "Meta Llama 3.2 11B Vision Instruct",
          "type": "Text",
          "description": "Compact vision-instruct model.",
          "contextWindows": "128k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "4",
          "name": "Meta Llama 3.2 3B Instruct",
          "type": "Text",
          "description": "Lightweight instruction-following model.",
          "contextWindows": "128k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "5",
          "name": "Meta Llama 3.2 1B Instruct",
          "type": "Text",
          "description": "Small-scale instruction model.",
          "contextWindows": "128k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "6",
          "name": "Meta Llama 3.1 405B Instruct",
          "type": "Text",
          "description": "Large-scale instruction-following model for complex tasks.",
          "contextWindows": "Pricey Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "7",
          "name": "Meta Llama 3.1 70B Instruct Turbo",
          "type": "Text",
          "description": "Optimized instruction model.",
          "contextWindows": "Not listed Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "8",
          "name": "Meta Llama V3 8B",
          "type": "Text",
          "description": "Standard model for general tasks.",
          "contextWindows": "8k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "9",
          "name": "Meta Llama V3 8B Instruct",
          "type": "Text",
          "description": "Enhanced instruction-following model.",
          "contextWindows": "8k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "10",
          "name": "Meta Llama V3 70B Instruct",
          "type": "Text",
          "description": "High-performance instruction-following model.",
          "contextWindows": "8k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "11",
          "name": "Meta Llama V2 13B",
          "type": "Text",
          "description": "Previous-generation model with moderate scale.",
          "contextWindows": "4k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "12",
          "name": "Meta Llama V2 13B Chat",
          "type": "Text",
          "description": "Chat-optimized model for interactive tasks.",
          "contextWindows": "4k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "13",
          "name": "Meta Llama V2 7B Chat (Fp16)",
          "type": "Text",
          "description": "Chat model with FP16 precision.",
          "contextWindows": "4k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "14",
          "name": "Meta Llama V2 7B Chat (Int8)",
          "type": "Text",
          "description": "Chat model with Int8 precision.",
          "contextWindows": "4k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "15",
          "name": "Meta Llama V2 7B Chat Hf Lora",
          "type": "Text",
          "description": "Chat model fine-tuned with LoRA.",
          "contextWindows": "4k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "16",
          "name": "Meta Llama Guard 7B",
          "type": "Text",
          "description": "Security-focused model.",
          "contextWindows": "2k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        }
      ]
    },
    "Nvidia": {
      "companyInfo": {
        "name": "Nvidia",
        "organizationName": "Nvidia Corporation"
      },
      "models": [
        {
          "number": "1",
          "name": "Nvidia Llama Models",
          "type": "Text",
          "description": " Text generation models developed by Nvidia.",
          "contextWindows": "Not listed Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        }
      ]
    },

    "Xai Grok 2": {
      "companyInfo": {
        "name": "Xai",
        "organizationName": "Xai AI"
      },
      "models": [
        {
          "number": "1",
          "name": "Grok 2Xai Vision",
          "type": "Text",
          "description": "Vision model with advanced capabilities.",
          "contextWindows": "32k (Pricey) Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "2",
          "name": "Grok 2Xai",
          "type": "Text",
          "description": "Text model with advanced capabilities.",
          "contextWindows": "32k (Pricey) Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "3",
          "name": "Grok 2Xai mini",
          "type": "Text",
          "description": "Compact text model with advanced capabilities.",
          "contextWindows": "32k (Pricey) Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        }
      ]
    },
    "Ministral Models": {
      "companyInfo": {
        "name": "Ministral",
        "organizationName": "Ministral AI"
      },
      "models": [
        {
          "number": "1",
          "name": "Mistral Small",
          "type": "Text",
          "description": "Compact model for efficient text generation.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "2",
          "name": "Mistral Tiny",
          "type": "Text",
          "description": "Lightweight model for small-scale text tasks.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "3",
          "name": "Mistral 7B Instruct",
          "type": "Text",
          "description": "Instruction-following model with moderate scale.",
          "contextWindows": "8k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "4",
          "name": "Mistral 7B Instruct V0.1",
          "type": "Text",
          "description": "Initial version of the 7B instruction-following model.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "5",
          "name": "Mistral 7B Instruct V0.1 Awq",
          "type": "Text",
          "description": "Awq-optimized version of the 7B instruction model.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "6",
          "name": "Mistral 7B Instruct V0.2",
          "type": "Text",
          "description": "Enhanced instruction-following model, version 0.2.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "7",
          "name": "Mistral 7B Instruct V0.2 Lora",
          "type": "Text",
          "description": "LoRA fine-tuned version of the 7B instruction model.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "8",
          "name": "Mixtral 8×7B Instruct",
          "type": "Text",
          "description": "Multi-instance 7B instruction-following model.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "9",
          "name": "Mixtral 8×7B (Base)",
          "type": "Text",
          "description": "Base configuration of the multi-instance 7B model.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "10",
          "name": "Mixtral 8×7B (Groq)",
          "type": "Text",
          "description": "Optimized for Groq hardware, multi-instance 7B model.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "11",
          "name": "Mixtral 8×22B",
          "type": "Text",
          "description": "High-performance 22B multi-instance model.",
          "contextWindows": "64k Tokens",
          "promptTemplate": "",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "12",
          "name": "Ministral 8B",
          "type": "Text",
          "description": "Large-scale text generation model optimized for long contexts.",
          "contextWindows": "128k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "13",
          "name": "Ministral 3B",
          "type": "Text",
          "description": "Text generation model with advanced capabilities for handling complex prompts.",
          "contextWindows": "128k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "14",
          "name": "Mistral Large",
          "type": "Text",
          "description": "Large-scale text generation model optimized for long contexts.",
          "contextWindows": "128k (Pricey) Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        },
        {
          "number": "15",
          "name": "Mistral Medium",
          "type": "Text",
          "description": "Text generation model with advanced capabilities for handling complex prompts.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/image3.svg"
        }
      ]
    },
    "Amazon Models": {
      "companyInfo": {
        "name": "Amazon",
        "organizationName": "Amazon Web Services (AWS)"
      },
      "models": [
        {
          "number": "1",
          "name": "Nova Micro",
          "type": "Text",
          "description": "Compact text model optimized for long contexts.",
          "contextWindows": "128k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/amazon-nova-micro.svg"
        },
        {
          "number": "2",
          "name": "Nova Lite",
          "type": "Text",
          "description": "Lightweight model designed for extended context capabilities.",
          "contextWindows": "300k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/amazon-nova-lite.svg"
        },
        {
          "number": "3",
          "name": "Nova Pro",
          "type": "Text",
          "description": "High-performance model with exceptional context handling.",
          "contextWindows": "300k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/amazon-nova-pro.svg"
        },
        {
          "number": "4",
          "name": "Titan Text Lite",
          "type": "Text",
          "description": "Entry-level model for short context tasks.",
          "contextWindows": "4k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/amazon-titan-text-lite.svg"
        },
        {
          "number": "5",
          "name": "Titan Text Express",
          "type": "Text",
          "description": "Balanced model with support for moderately extended contexts.",
          "contextWindows": "8k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/amazon-titan-text-express.svg"
        },
        {
          "number": "6",
          "name": "Titan Text Premier",
          "type": "Text",
          "description": "Premium text model for handling extended contexts and complex tasks.",
          "contextWindows": "32k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/amazon-titan-text-premier.svg"
        }
      ]
    },

    "Cohere Models": {
      "companyInfo": {
        "name": "Cohere",
        "organizationName": "Cohere AI"
      },
      "models": [
        {
          "number": "1",
          "name": "Command R+",
          "type": "Text",
          "description": "Enhanced retrieval-augmented model for large-scale tasks.",
          "contextWindows": "128k (Pricey) Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/cohere-command-r-plus.svg"
        },
        {
          "number": "2",
          "name": "Command R",
          "type": "Text",
          "description": "Retrieval-augmented model optimized for long contexts.",
          "contextWindows": "128k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/cohere-command-r.svg"
        },
        {
          "number": "3",
          "name": "Command",
          "type": "Text",
          "description": "General-purpose text generation model.",
          "contextWindows": "4k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/cohere-command.svg"
        },
        {
          "number": "4",
          "name": "Command Light",
          "type": "Text",
          "description": "Lightweight model for small-scale tasks.",
          "contextWindows": "4k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/cohere-command-light.svg"
        }
      ]
    },
    "Microsoft Models": {
      "companyInfo": {
        "name": "Microsoft",
        "organizationName": "Microsoft Corporation"
      },
      "models": [
        {
          "number": "1",
          "name": "Wizardlm-2 8×22B",
          "type": "Text",
          "description": "High-performance large-scale model optimized for extended contexts.",
          "contextWindows": "64k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/microsoft-wizardlm-8x22b.svg"
        },
        {
          "number": "2",
          "name": "Wizardlm-2 7B",
          "type": "Text",
          "description": "Compact model for handling moderately long contexts.",
          "contextWindows": "31k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/microsoft-wizardlm-7b.svg"
        },
        {
          "number": "3",
          "name": "Phi 2",
          "type": "Text",
          "description": "Efficient small-scale text generation model.",
          "contextWindows": "2k Tokens",
          "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
          "systemPrompt": "",
          "icon": "images/microsoft-phi-2.svg"
        }
      ]
    }
  }
}
